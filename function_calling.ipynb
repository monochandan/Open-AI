{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f7746617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")\n",
    "## https://platform.openai.com/tokenizer\n",
    "## https://openai.com/pricing#language-models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2db79f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dde622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## call the model\n",
    "#from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "#process.env.API_KEY\n",
    "\n",
    "openai.api_key  = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5d594",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae64d191",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'ListModels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23260\\943953962.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mallmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListModels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'openai' has no attribute 'ListModels'"
     ]
    }
   ],
   "source": [
    "allmodels = openai.ListModels()\n",
    "print(allmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46964f73",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allmodels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23260\\3711517377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"created\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"object\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"owned_by\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'allmodels' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(list(allmodels), columns = [\"id\", \"created\", \"object\", \"owned_by\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ac3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(allmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "70a5d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate openai key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c3c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c311189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### openai playground : chat completion API and function calling\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-0125\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"How can I make money?\" ## direct question: 0-shot prompt\n",
    "    }\n",
    "  ],\n",
    "    max_tokens = 100,\n",
    "    n = 3\n",
    ")\n",
    "\n",
    "#   ##temperature=1,\n",
    "#   ##max_tokens=256,\n",
    "#   top_p=1,\n",
    "#   frequency_penalty=0,\n",
    "#   presence_penalty=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d82a9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "## different parameters inside the methods\n",
    "# model = \"\"\n",
    "# prompt = input prompt\n",
    "# max_tokens = in how many number of tokens you want result\n",
    "# temprature = for getting some creative output\n",
    "# n = number of the output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df00a8c3",
   "metadata": {},
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "963fb613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are many ways to make money, depending on your skills, interests, and goals. Here are some common ways to make money:\\n\\n1. Get a job: This is the most traditional way to make money. Look for job opportunities in your area or online, and apply for positions that match your skills and experience.\\n\\n2. Start a side hustle: If you have a passion or hobby that you can monetize, consider starting a side hustle. This could involve selling handmade goods, offering freelance services'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print the response\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0922972",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function calling\n",
    "## langchain -- openai use via langchain, prompt template\n",
    "\n",
    "## hugging face with langchain\n",
    "\n",
    "## chain\n",
    "## agents\n",
    "## memory by using langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "192756d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\n\nFor further information visit https://errors.pydantic.dev/2.5/u/root-validator-pre-skip",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24672\\3145503717.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\openai\\lib\\site-packages\\langchain\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMRKLChain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReActChain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSelfAskWithSearchChain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m from langchain.chains import (\n\u001b[0;32m     10\u001b[0m     \u001b[0mConversationChain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\openai\\lib\\site-packages\\langchain\\agents\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"Routing chains.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitialize_agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMRKLChain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZeroShotAgent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreact\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReActChain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReActTextWorldAgent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\openai\\lib\\site-packages\\langchain\\agents\\agent.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mChain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mllm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mChainedInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_color_mapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mllms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLLM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\openai\\lib\\site-packages\\langchain\\chains\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"Chains are easily reusable components which can be linked together.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconversation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConversationChain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mllm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mllm_math\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLLMMathChain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPALChain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\openai\\lib\\site-packages\\langchain\\chains\\conversation\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconversation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConversationBufferMemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconversation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPROMPT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mllm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\openai\\lib\\site-packages\\langchain\\chains\\conversation\\memory.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconversation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSUMMARY_PROMPT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mllm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mllms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLLM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\openai\\lib\\site-packages\\langchain\\chains\\conversation\\prompt.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# flake8: noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m _DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\openai\\lib\\site-packages\\langchain\\prompts\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"Prompt template classes.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBasePromptTemplate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfew_shot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFewShotPromptTemplate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_prompt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPrompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\openai\\lib\\site-packages\\langchain\\prompts\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mBasePromptTemplate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[1;34m\"\"\"Base prompt should expose the format method, returning a prompt.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\openai\\lib\\site-packages\\langchain\\prompts\\base.py\u001b[0m in \u001b[0;36mBasePromptTemplate\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;34m\"\"\"A list of the names of the variables the prompt template expects.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[1;33m@\u001b[0m\u001b[0mroot_validator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvalidate_variable_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;34m\"\"\"Validate variable names do not restricted names.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\openai\\lib\\site-packages\\pydantic\\deprecated\\class_validators.py\u001b[0m in \u001b[0;36mroot_validator\u001b[1;34m(pre, skip_on_failure, allow_reuse, *__args)\u001b[0m\n",
      "\u001b[1;31mPydanticUserError\u001b[0m: If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\n\nFor further information visit https://errors.pydantic.dev/2.5/u/root-validator-pre-skip"
     ]
    }
   ],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9297b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description = \"My name is MKDC. I am a student of Data Science at the university of Trier. I have medium level of programming skills and I am active member of the University's AI club. I hope that I will create a company as OpenAI. I thougth the name, It will be CloseAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ec5f3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My name is MKDC. I am a student of Data Science at the university of Trier. I have medium level of programming skills and I am active member of the University's AI club. I hope that I will create a company as OpenAI. I thougth the name, It will be CloseAI\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21abcd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## few shot prompt\n",
    "prompt = f'''\n",
    "Please extract the following information from the given text and return it as JASON object:\n",
    "\n",
    "\n",
    "name\n",
    "college\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_description}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "757ece72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPlease extract the following information from the given text and return it as JASON object:\\n\\n\\nname\\ncollege\\ngrades\\nclub\\n\\nThis is the body of text to extract the information from:\\nMy name is MKDC. I am a student of Data Science at the university of Trier. I have medium level of programming skills and I am active member of the University's AI club. I hope that I will create a company as OpenAI. I thougth the name, It will be CloseAI\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c36e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = mykey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70ed6099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x13c0611ff48>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a51a0bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-0125\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt ## few-shot prompt\n",
    "    }\n",
    "  ],\n",
    "    max_tokens = 100,\n",
    "    n = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df835a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9F9XFsPHT60kQQjbT5CxHEmMic8fR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"name\": \"MKDC\",\\n  \"college\": \"University of Trier\",\\n  \"grades\": \"medium level of programming skills\",\\n  \"club\": \"University\\'s AI club\"\\n}', role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=1, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"name\": \"MKDC\",\\n  \"college\": \"University of Trier\",\\n  \"grades\": \"medium level of programming skills\",\\n  \"club\": \"University\\'s AI club\"\\n}', role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=2, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"name\": \"MKDC\",\\n  \"college\": \"University of Trier\",\\n  \"grades\": \"medium level of programming skills\",\\n  \"club\": \"University\\'s AI club\"\\n}', role='assistant', function_call=None, tool_calls=None))], created=1713398601, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_c2295e73ad', usage=CompletionUsage(completion_tokens=123, prompt_tokens=109, total_tokens=232))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d917b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e69ae8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9a1aa5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'MKDC',\n",
       " 'college': 'University of Trier',\n",
       " 'grades': 'medium level of programming skills',\n",
       " 'club': \"University's AI club\"}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96653918",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://platform.openai.com/docs/guides/function-calling \n",
    "## FUNCTION CALLING\n",
    "student_custom_function = [\n",
    "        {\n",
    "            'name': 'extract_student_info',\n",
    "            'description': 'Get the student information from the body of the input text',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    \n",
    "                    'name':{\n",
    "                        'type':'string',\n",
    "                        'description': 'Name of the person'\n",
    "                    },\n",
    "                    \n",
    "                    'school':{\n",
    "                        'type': 'string',\n",
    "                        'derscription': 'The college name.'\n",
    "                    },\n",
    "                    \n",
    "                    'grades':{\n",
    "                        'type': 'integer',\n",
    "                        'description': 'The college name.'\n",
    "                        \n",
    "                    },\n",
    "                    'club':{\n",
    "                        'type': 'string',\n",
    "                        'description': 'college club for extracurricular activities. '\n",
    "                    }\n",
    "                    \n",
    "                }\n",
    "                \n",
    "            }\n",
    "           \n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85165e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-0125\",\n",
    "  messages=[{\"role\": \"user\",\"content\": prompt }],\n",
    "    functions = student_custom_function,\n",
    "    max_tokens = 100,\n",
    "    n = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6addecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9FAVu8lFiWXC0L1mHktr0lNjadUFq', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"name\":\"MKDC\",\"school\":\"University of Trier\",\"grades\":null,\"club\":\"University\\'s AI club\"}', name='extract_student_info'), tool_calls=None)), Choice(finish_reason='function_call', index=1, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{}', name='extract_student_info'), tool_calls=None)), Choice(finish_reason='function_call', index=2, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{}', name='extract_student_info'), tool_calls=None))], created=1713402362, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_c2295e73ad', usage=CompletionUsage(completion_tokens=56, prompt_tokens=187, total_tokens=243))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa3dc9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"name\":\"MKDC\",\"school\":\"University of Trier\",\"grades\":null,\"club\":\"University\\'s AI club\"}', name='extract_student_info'), tool_calls=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19c4134b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\":\"MKDC\",\"school\":\"University of Trier\",\"grades\":null,\"club\":\"University\\'s AI club\"}'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d706c8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'MKDC',\n",
       " 'school': 'University of Trier',\n",
       " 'grades': None,\n",
       " 'club': \"University's AI club\"}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c95d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description_1 = \"My name is MKFC. I am a student of Data Science at the university of Hamburg. I have medium level of programming skills and I am active member of the University's AGI club. I hope that I will create a company as OpenAI. I thougth the name, It will be SemiOpenAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b65b260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'MKDC', 'school': 'University of Trier', 'grades': 3, 'club': 'AI club'}\n",
      "{'name': 'MKFC', 'school': 'University of Hamburg', 'grades': 3, 'club': 'AGI club'}\n"
     ]
    }
   ],
   "source": [
    "student_info = [student_description, student_description_1] ## list of students\n",
    "for stu in student_info:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"user\",\"content\": stu }],\n",
    "        functions = student_custom_function,\n",
    "        function_call = 'auto'\n",
    "        \n",
    "    )\n",
    "    \n",
    "    response = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "395c244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_two =  [\n",
    "        {\n",
    "            'name': 'extract_student_info',\n",
    "            'description': 'Get the student information from the body of the input text',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    \n",
    "                    'name':{\n",
    "                        'type':'string',\n",
    "                        'description': 'Name of the person'\n",
    "                    }\n",
    "                    \n",
    "                }\n",
    "                \n",
    "            }\n",
    "           \n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8bf89d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'MKDC', 'college': 'University of Trier', 'grades': 3, 'club': 'AI club'}\n",
      "{'name': 'MKFC', 'college': 'University of Hamburg', 'grades': 6, 'club': 'AGI club'}\n"
     ]
    }
   ],
   "source": [
    "## calling multiple function instead multiple variables\n",
    "function_list = [student_custom_function[0], function_two[0]] ## list of functions\n",
    "student_list = [student_description, student_description_1] ## list of students\n",
    "\n",
    "for stu in student_info:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"user\",\"content\": stu }],\n",
    "        functions = function_list,\n",
    "        function_call = 'auto'\n",
    "        \n",
    "    )\n",
    "    \n",
    "    response = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "848e580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## advance example of function call\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo-0125\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"When is the next flight from Frankfurt to Dhaka?\"\n",
    "        }\n",
    "        \n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fcacaef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I am an AI assistant and do not have real-time flight information. I recommend checking with the airline or using a flight tracking website for the most accurate and up-to-date information on flight schedules.\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2bc880ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_descriptions = [\n",
    "    {\n",
    "        \"name\": \"get_flight_info\",\n",
    "        \"description\": \"Get flight information between two locations\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"loc_origin\": {\n",
    "                    \"type\":\"string\",\n",
    "                    \"description\": \"The deperature airport, e.g. DUS\",\n",
    "                    \n",
    "                },\n",
    "                \"loc_destination\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The destination airport, e.g. DUS\",\n",
    "                }\n",
    "                \n",
    "            },\n",
    "             \"required\":[\"loc_origin\", \"loc_destination\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ebddcef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function_descriptions = [\n",
    "#     {\n",
    "#         \"name\": \"get_flight_info\",\n",
    "#         \"description\": \"Get flight information between two locations\",\n",
    "#         \"parameters\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"loc_origin\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": \"The departure airport, e.g., DUS\"\n",
    "#                 },\n",
    "#                 \"loc_destination\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": \"The destination airport, e.g., DUS\"\n",
    "#                 }\n",
    "#             },\n",
    "#             \"required\": [\"loc_origin\", \"loc_destination\"]\n",
    "#         }\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e27f6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt = \"when is the next flight from frankfurt to Dhaka?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3b546888",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo-0125\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\":input_prompt\n",
    "        }\n",
    "    ],\n",
    "    ## add function calling\n",
    "    functions = output_descriptions,\n",
    "    ##specify the function call\n",
    "    function_call = 'auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ff55702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "16844c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"loc_origin\":\"FRA\",\"loc_destination\":\"DAC\"}', name='get_flight_info'), tool_calls=None)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "83fab0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"loc_origin\":\"FRA\",\"loc_destination\":\"DAC\"}'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e487984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "866f09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dummy API\n",
    "def get_flight_info(loc_origin, loc_destination):\n",
    "    \"\"\"get flight destination between 2 locations\"\"\"\n",
    "    \n",
    "    # example output return from API or database\n",
    "    \n",
    "    flight_info = {\n",
    "        \"lc_origin\": loc_origin,\n",
    "        \"lc_destination\": loc_destination,\n",
    "        \"datetime\": str(datetime.now() + timedelta(hours = 2)),\n",
    "        \"airline\": \"KLM\",\n",
    "        \"flight\": \"KL643\",\n",
    "    }\n",
    "    \n",
    "    return json.dumps(flight_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "56d7bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = json.loads(response_2.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "424b9c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc_origin': 'FRA', 'loc_destination': 'DAC'}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5be8feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = params.get(\"loc_origin\")\n",
    "destination = params.get(\"loc_destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bc4cf864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_flight_info'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2.choices[0].message.function_call.name ## from output_description --> name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fa0c5322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response_2.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7afe2ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_function = eval(response_2.choices[0].message.function_call.name) ## eval will give the actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ba6fd763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_flight_info(loc_origin, loc_destination)>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "84e285c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0fed545c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval('2') ## converting into the original formate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f24d4da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"lc_origin\": \"FRA\", \"lc_destination\": \"DAC\", \"datetime\": \"2024-04-18 06:33:40.884169\", \"airline\": \"KLM\", \"flight\": \"KL643\"}\n"
     ]
    }
   ],
   "source": [
    "flight = chosen_function(**params)\n",
    "print(flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d07357ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_3 = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo-0125\",\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": input_prompt}, ## user asking question\n",
    "        {\"role\": \"function\",\"name\": response_2.choices[0].message.function_call.name,\"content\":flight} ## output are comming from function\n",
    "        \n",
    "    ],\n",
    "    ## add function calling\n",
    "    functions = output_descriptions,\n",
    "    ##specify the function call\n",
    "    function_call = 'auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0721da2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9FC0mMdjJE7W273oLC8b0wGGwmXUc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The next flight from Frankfurt (FRA) to Dhaka (DAC) is on April 18, 2024, at 06:33. The flight is operated by KLM with flight number KL643.', role='assistant', function_call=None, tool_calls=None))], created=1713408120, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_c2295e73ad', usage=CompletionUsage(completion_tokens=45, prompt_tokens=143, total_tokens=188))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c8422736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The next flight from Frankfurt (FRA) to Dhaka (DAC) is on April 18, 2024, at 06:33. The flight is operated by KLM with flight number KL643.'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_3.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c6eefa",
   "metadata": {},
   "source": [
    "#### FUNCTION CALLING: learn how to connect large language models to extarnal tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67e135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
