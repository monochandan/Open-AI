{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11fa9cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "#from openai import OpenAI\n",
    "import os\n",
    "from const import mykey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf202ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45adc4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ef427d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7b17f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize openai\n",
    "llm = OpenAI(openai_api_key = api_key, model_name = \"gpt-3.5-turbo-0125\", temprature = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52153b84",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27368\\1864968198.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"can you tell me total country in Asia?\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# zero shot prompting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\openai\\lib\\site-packages\\langchain\\llms\\openai.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, prompt, stop)\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`stop` found in both the input and default params.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stop\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"choices\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\openai\\lib\\site-packages\\openai\\lib\\_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "x = llm(\"can you tell me total country in Asia?\") # zero shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e86de414",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OpenAI' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27368\\683636758.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'OpenAI' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "response = client.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c710594",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OpenAI' object has no attribute 'complete'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27368\\1216538226.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Generate text based on the prompt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Print the generated text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OpenAI' object has no attribute 'complete'"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client with your API key\n",
    "client = OpenAI(api_key=mykey)\n",
    "\n",
    "# Define a prompt\n",
    "prompt = \"Once upon a time,\"\n",
    "\n",
    "# Generate text based on the prompt\n",
    "response = client.complete(prompt)\n",
    "\n",
    "# Print the generated text\n",
    "print(\"Generated text:\", response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1cf66519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Config', '__abstractmethods__', '__annotations__', '__call__', '__class__', '__class_vars__', '__config__', '__custom_root_type__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__exclude_fields__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_validators__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__include_fields__', '__init__', '__init_subclass__', '__iter__', '__json_encoder__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__post_root_validators__', '__pre_root_validators__', '__pretty__', '__private_attributes__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__schema_cache__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__try_update_forward_refs__', '__validators__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_decompose_class', '_default_params', '_enforce_dict_if_root', '_get_value', '_identifying_params', '_init_private_attributes', '_iter', 'best_of', 'build_extra', 'client', 'construct', 'copy', 'dict', 'frequency_penalty', 'from_orm', 'json', 'max_tokens', 'model_kwargs', 'model_name', 'n', 'openai_api_key', 'parse_file', 'parse_obj', 'parse_raw', 'presence_penalty', 'schema', 'schema_json', 'temperature', 'top_p', 'update_forward_refs', 'validate', 'validate_environment']\n"
     ]
    }
   ],
   "source": [
    "print(dir(client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c0b7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "65d672ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"openai_api_key\"] = mykey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e44f9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 18:36:39.574 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\looka\\.conda\\envs\\openai\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "st.title('Langchain Demo with openai api')\n",
    "input_text = st.text_input(\"Search trhe topic u want\")\n",
    "llm = OpenAI(temprature = 0.8)\n",
    "\n",
    "if input_text:\n",
    "    st.write(llm(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7516845",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use openAi via langchain\n",
    "## prompt templeting\n",
    "## chains\n",
    "## agents -- serpAPI -- google search api\n",
    "## memory -- how to retain the memory\n",
    "## document loader\n",
    "## hugging face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c56285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## limitations of openAI API\n",
    "## openAI model is not free\n",
    "## traineed till sep 2021 data\n",
    "## langchain -- can access different llm model by using different API\n",
    "             ##-- can access private data sources\n",
    "             ##-- can access any third party API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
